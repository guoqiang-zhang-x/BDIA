{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## Faster GPUs\n",
        "\n",
        "<p>Users who have purchased one of Colab's paid plans have access to premium GPUs. You can upgrade your notebook's GPU settings in <code>Runtime &gt; Change runtime type</code> in the menu to enable Premium accelerator. Subject to availability, selecting a premium GPU may grant you access to a V100 or A100 Nvidia GPU.</p>\n",
        "<p>The free-of-charge version of Colab grants access to Nvidia's T4 GPUs subject to quota restrictions and availability.</p>\n",
        "\n",
        "You can see what GPU you've been assigned at any time by executing the following cell. If the execution result of running the code cell below is 'Not connected to a GPU', you can change the runtime by going to <code>Runtime &gt; Change runtime type</code> in the menu to enable a GPU accelerator, and then re-execute the code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23TOba33L4qf",
        "outputId": "fbaf7c65-2660-4a54-8439-f06b2b5e3592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Oct  4 13:04:20 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    24W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyShLzodykWv",
        "outputId": "06ecf0f2-df30-4888-b112-1523adf3a468"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5Ra2H0mgiec",
        "outputId": "fd9a03de-fea2-44a8-ad5a-9b912c7b7736"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')   # this leaves pwd at /content, not /content/drive\n",
        "!pwd\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6NlHI7mhBye",
        "outputId": "3609ad14-ed13-4e00-f1ac-10f061dba253"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 5, in <module>\n",
            "    from pip._internal.cli.main import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 10, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
            "    from pip._internal.build_env import get_runnable_pip\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/build_env.py\", line 19, in <module>\n",
            "    from pip._internal.cli.spinners import open_spinner\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n",
            "    from pip._internal.utils.logging import get_indentation\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 13, in <module>\n",
            "    from pip._vendor.rich.console import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/__init__.py\", line 17, in <module>\n",
            "    _IMPORT_CWD = os.path.abspath(os.getcwd())\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 5, in <module>\n",
            "    from pip._internal.cli.main import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 10, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
            "    from pip._internal.build_env import get_runnable_pip\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/build_env.py\", line 19, in <module>\n",
            "    from pip._internal.cli.spinners import open_spinner\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n",
            "    from pip._internal.utils.logging import get_indentation\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 13, in <module>\n",
            "    from pip._vendor.rich.console import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/__init__.py\", line 17, in <module>\n",
            "    _IMPORT_CWD = os.path.abspath(os.getcwd())\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 5, in <module>\n",
            "    from pip._internal.cli.main import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 10, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
            "    from pip._internal.build_env import get_runnable_pip\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/build_env.py\", line 19, in <module>\n",
            "    from pip._internal.cli.spinners import open_spinner\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n",
            "    from pip._internal.utils.logging import get_indentation\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 13, in <module>\n",
            "    from pip._vendor.rich.console import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/__init__.py\", line 17, in <module>\n",
            "    _IMPORT_CWD = os.path.abspath(os.getcwd())\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 5, in <module>\n",
            "    from pip._internal.cli.main import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 10, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
            "    from pip._internal.build_env import get_runnable_pip\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/build_env.py\", line 19, in <module>\n",
            "    from pip._internal.cli.spinners import open_spinner\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n",
            "    from pip._internal.utils.logging import get_indentation\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 13, in <module>\n",
            "    from pip._vendor.rich.console import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/__init__.py\", line 17, in <module>\n",
            "    _IMPORT_CWD = os.path.abspath(os.getcwd())\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-28-8222aa3df968>\", line 7, in <cell line: 7>\n",
            "    get_ipython().run_line_magic('cd', '/content/drive/MyDrive/EDICT-main')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2418, in run_line_magic\n",
            "    result = fn(*args, **kwargs)\n",
            "  File \"<decorator-gen-85>\", line 2, in cd\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\", line 187, in <lambda>\n",
            "    call = lambda f, *a, **k: f(*a, **k)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py\", line 342, in cd\n",
            "    oldcwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-28-8222aa3df968>\", line 7, in <cell line: 7>\n",
            "    get_ipython().run_line_magic('cd', '/content/drive/MyDrive/EDICT-main')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2418, in run_line_magic\n",
            "    result = fn(*args, **kwargs)\n",
            "  File \"<decorator-gen-85>\", line 2, in cd\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\", line 187, in <lambda>\n",
            "    call = lambda f, *a, **k: f(*a, **k)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py\", line 342, in cd\n",
            "    oldcwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-28-8222aa3df968>\", line 7, in <cell line: 7>\n",
            "    get_ipython().run_line_magic('cd', '/content/drive/MyDrive/EDICT-main')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2418, in run_line_magic\n",
            "    result = fn(*args, **kwargs)\n",
            "  File \"<decorator-gen-85>\", line 2, in cd\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\", line 187, in <lambda>\n",
            "    call = lambda f, *a, **k: f(*a, **k)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py\", line 342, in cd\n",
            "    oldcwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
            "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.30.2\n",
        "!pip install omegaconf\n",
        "#!pip install diffusers\n",
        "!pip install diffusers==0.20.0\n",
        "#!pip install accelerate\n",
        "!pip install torchmetrics\n",
        "%cd /content/drive/MyDrive/EDICT-main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "maA8CDfoTwdK",
        "outputId": "56468d59-d8d4-4625-bcf6-76ae494d9c77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-20 17:41:40.599385: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-20 17:41:40.599432: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-20 17:41:40.599462: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-20 17:41:41.734472: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "vocab.json: 100% 961k/961k [00:00<00:00, 4.06MB/s]\n",
            "merges.txt: 100% 525k/525k [00:00<00:00, 52.1MB/s]\n",
            "special_tokens_map.json: 100% 389/389 [00:00<00:00, 2.40MB/s]\n",
            "tokenizer_config.json: 100% 905/905 [00:00<00:00, 5.11MB/s]\n",
            "config.json: 100% 4.52k/4.52k [00:00<00:00, 21.1MB/s]\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "model.safetensors: 100% 1.71G/1.71G [00:05<00:00, 287MB/s]\n",
            "unet/config.json: 100% 772/772 [00:00<00:00, 4.29MB/s]\n",
            "diffusion_pytorch_model.bin: 100% 1.72G/1.72G [00:03<00:00, 437MB/s]\n",
            "vae/config.json: 100% 550/550 [00:00<00:00, 3.22MB/s]\n",
            "diffusion_pytorch_model.bin: 100% 167M/167M [00:00<00:00, 544MB/s]\n",
            "Loaded all models\n",
            "saving to img_edit_imagenetlake/BDIA_dodiff_V5_tiger_scale_3_gamma_0.98.png\n",
            " 52% 21/40 [02:51<02:39,  8.40s/it]"
          ]
        }
      ],
      "source": [
        "!python bdia_edit.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iLw_YVq3Ln9"
      },
      "outputs": [],
      "source": [
        "def plot_EDICT_outputs(im_tuple):\n",
        "    fig, (ax0, ax1) = plt.subplots(1, 2)\n",
        "    ax0.imshow(im_tuple[0])\n",
        "    ax1.imshow(im_tuple[1])\n",
        "    #plt.show()\n",
        "    plt.savefig('test.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tceDS2ue0r7D"
      },
      "outputs": [],
      "source": [
        "# @title main(cleaned)\n",
        "\n",
        "from edict_functions import *\n",
        "# from jax._src.tree_util import tree_unflatten\n",
        "\n",
        "PROMPT_EXTRA = \", hyper realistic, minutely detailed\"\n",
        "\n",
        "EXPERIMENT = \"woman\"\n",
        "\n",
        "\n",
        "if EXPERIMENT == \"woman\":\n",
        "  imgpath = 'experiment_images/woman-657753_512.jpg'\n",
        "  base_prompt = 'a photograph of a blonde woman' + PROMPT_EXTRA\n",
        "  prompt_list = [(\"old\",    \"an old woman\"),   # (fileword, prompt)\n",
        "                  (\"girl\",  \"a girl\"),\n",
        "                 # (\"redhair\",   \"photograph of a woman with red hair\" + PROMPT_EXTRA)\n",
        "                ]\n",
        "\n",
        "if EXPERIMENT == \"dog\":\n",
        "  imgpath = 'images/animal-3414131_512.jpg'\n",
        "  base_prompt = 'a poodle dog'\n",
        "  prompt_list = [(\"statue\",    \"a huge metallic statue of a dog\"),\n",
        "                  (\"huge\",  \"a Black and white photo of huge dog above a city\" + PROMPT_EXTRA),\n",
        "                  (\"moon\",   \"a black and whilte photo of a poodle dog on the moon\" + PROMPT_EXTRA),\n",
        "                ]\n",
        "\n",
        "\n",
        "if EXPERIMENT == \"monalisa\":\n",
        "  imgpath = \"images/monalisa_art-74050_512.png\"\n",
        "  base_prompt = \"a painting of a woman\"\n",
        "  prompt_list = [(\"concert\",    \"a photo of a woman at a rock concert\" + PROMPT_EXTRA),\n",
        "                 # (\"underwater\",    \"a photo portrait of a woman underwater with fish\" + PROMPT_EXTRA),\n",
        "                ]\n",
        "\n",
        "\n",
        "if EXPERIMENT == \"cow\":\n",
        "  imgpath = \"images/cow-2132526_512.png\"\n",
        "  base_prompt = \"a photograph of cow in a field\"\n",
        "  prompt_list = [(\"city\",    \"a photograph of a cow in the city\" + PROMPT_EXTRA),\n",
        "                 (\"desert\",    \"a photograph of a cow in the desert\" + PROMPT_EXTRA),\n",
        "                ]\n",
        "\n",
        "if EXPERIMENT == \"plane\":\n",
        "  imgpath = \"images/plane-1506313_512.png\"\n",
        "  base_prompt = \"a photograph of a crashed plane\"\n",
        "  prompt_list = [(\"moon\",    \"a photograph of a secret crashed spaceship on the moon\" + PROMPT_EXTRA),\n",
        "                 (\"ufo\",    \"a photograph of a crashed alien UFO wreckage\" + PROMPT_EXTRA),\n",
        "                 (\"desert\",    \"a photograph of a crashed plane in the desert\" + PROMPT_EXTRA),\n",
        "                ]\n",
        "\n",
        "im = load_im_into_format_from_path(imgpath)\n",
        "im.save(f\"{EXPERIMENT}_original.png\",\"PNG\")\n",
        "for (i,e) in enumerate(prompt_list):\n",
        "  edit_prompt = e[1]\n",
        "  print(edit_prompt)\n",
        "  outpath = f\"_{EXPERIMENT}_{e[0]}.png\"\n",
        "  print(f\"saving to {outpath}\")\n",
        "  im_edit=BDIAV3_editing(imgpath, base_prompt, edit_prompt, gamma=1.0, steps=50)\n",
        "  im_edit[0].save(outpath, \"PNG\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxVzBQp8HZRK"
      },
      "source": [
        "# - end of notebook -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1-dwHU8c335"
      },
      "outputs": [],
      "source": [
        "#@title EDICT.py original\n",
        "raise(\"stop here\")\n",
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "# # Before Using this notebook\n",
        "# Put a copy of a suitable [HF Auth Token](https://huggingface.co/docs/hub/security-tokens) in a file named `hf_auth` with no new line (to be read by the following code in `edict_functions.py`)\n",
        "# ```\n",
        "# with open('hf_auth', 'r') as f:\n",
        "#     auth_token = f.readlines()[0].strip()\n",
        "#\n",
        "# ```\n",
        "#\n",
        "# Example file at `./hf_auth`\n",
        "# ```\n",
        "# abc123abc123\n",
        "# ```\n",
        "#\n",
        "#\n",
        "# Also, run  `conda env create -f environment.yaml`, activate that conda env (`conda activate edict`). Run jupyter with that conda env active\n",
        "\n",
        "# In[1]:\n",
        "\n",
        "\n",
        "from edict_functions import *\n",
        "from jax._src.tree_util import tree_unflatten\n",
        "\n",
        "\n",
        "# # Generations\n",
        "#\n",
        "# To run a novel EDICT generation, use `coupled_stablediffusion(my_prompt)`. This function also takes a steps kwarg that defaults to 50 (can be helpful for more complex generations but rarely needed).\n",
        "#\n",
        "# EDICT doesn't offer new capabilities for straight-up text-to-image generation, but it's a good sanity check to see how good the generative process we're relying on is.\n",
        "#\n",
        "\n",
        "# In[2]:\n",
        "\n",
        "\n",
        "def plot_EDICT_outputs(im_tuple):\n",
        "    fig, (ax0, ax1) = plt.subplots(1, 2)\n",
        "    ax0.imshow(im_tuple[0])\n",
        "    ax1.imshow(im_tuple[1])\n",
        "    #plt.show()\n",
        "    plt.savefig('test.png', bbox_inches='tight')\n",
        "\n",
        "\n",
        "# In[3]:\n",
        "\n",
        "\n",
        "#plot_EDICT_outputs(coupled_stablediffusion('A black bear'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#plot_EDICT_outputs(coupled_stablediffusion('A statue of a horse'))\n",
        "\n",
        "\n",
        "###########################################################\n",
        "# # Reconstruction\n",
        "#\n",
        "# Given an image (`x0`), we can invert it into latents `(xt,yt)` and reconstruct it with EDICT passes in different directtions.\n",
        "#\n",
        "# `run_baseline=True` is the DDIM-C baseline method from our paper, to run DDIM-UC `prompt` should be the empty string `''`\n",
        "\n",
        "# In[5]:\n",
        "\n",
        "'''\n",
        "#testing EDICT\n",
        "\n",
        "#im = load_im_into_format_from_path('experiment_images/church.jpg')\n",
        "#im = load_im_into_format_from_path('experiment_images/imagenet_dog_2.jpg')\n",
        "#im = load_im_into_format_from_path('experiment_images/pizza.jpg')\n",
        "im = load_im_into_format_from_path('experiment_images/bear.jpg')\n",
        "\n",
        "\n",
        "#im = load_im_into_format_from_path('experiment_images/rooster.JPEG')\n",
        "\n",
        "\n",
        "#prompt = 'A dog'\n",
        "prompt = 'A bear'\n",
        "\n",
        "\n",
        "#prompt = 'A church'\n",
        "run_baseline = False\n",
        "\n",
        "latents = BDIA_stablediffusion(prompt,\n",
        "                                reverse=True,\n",
        "                                init_image=im,\n",
        "                                steps = 50,\n",
        "                                guidance_scale = 7.0,\n",
        "                                run_baseline=run_baseline,\n",
        "                                )\n",
        "if run_baseline:\n",
        "    latents = latents[0]\n",
        "\n",
        "recon = BDIA_stablediffusion(prompt,\n",
        "                              reverse=False,\n",
        "                              steps = 50,\n",
        "                              guidance_scale = 7.0,\n",
        "                              fixed_starting_latent=latents,\n",
        "                              run_baseline=run_baseline,\n",
        "                              )\n",
        "recon = recon[0]\n",
        "\n",
        "#im.save(\"person-orig.png\",\"PNG\")\n",
        "recon.save(\"bear-rec_BDIA.png\",\"PNG\")\n",
        "\n",
        "\n",
        "\n",
        "run_baseline = True\n",
        "\n",
        "latents = coupled_stablediffusion(prompt,\n",
        "                               reverse=True,\n",
        "                                init_image=im,\n",
        "                                guidance_scale = 7.0,\n",
        "                                run_baseline=run_baseline,\n",
        "                               )\n",
        "if run_baseline:\n",
        "    latents = latents[0]\n",
        "\n",
        "recon = coupled_stablediffusion(prompt,\n",
        "                               reverse=False,\n",
        "                               guidance_scale = 7.0,\n",
        "                                fixed_starting_latent=latents,\n",
        "                                run_baseline=run_baseline,\n",
        "                               )\n",
        "recon = recon[0]\n",
        "im.save(\"bear-orig.png\",\"PNG\")\n",
        "recon.save(\"bear-rec_DDIM.png\",\"PNG\")\n",
        "\n",
        "'''\n",
        "\n",
        "#fig, (ax0, ax1) = plt.subplots(1,2)\n",
        "#ax0.imshow(im)\n",
        "#ax0.set_title(\"Original\")\n",
        "#ax1.imshow(recon)\n",
        "#ax1.set_title(\"Recon\")\n",
        "#plt.tight_layout()\n",
        "#plt.savefig('rooster_combine.png', bbox_inches='tight')\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "#testing EDICT\n",
        "im = load_im_into_format_from_path('experiment_images/church.jpg')\n",
        "prompt = 'A church'\n",
        "run_baseline = False\n",
        "\n",
        "latents = coupled_stablediffusion(prompt,\n",
        "                               reverse=True,\n",
        "                                init_image=im,\n",
        "                                run_baseline=run_baseline,\n",
        "                               )\n",
        "if run_baseline:\n",
        "    latents = latents[0]\n",
        "\n",
        "print(\"I am here main\")\n",
        "recon = coupled_stablediffusion(prompt,\n",
        "                               reverse=False,\n",
        "                                fixed_starting_latent=latents,\n",
        "                                run_baseline=run_baseline,\n",
        "                               )\n",
        "recon = recon[0]\n",
        "\n",
        "fig, (ax0, ax1) = plt.subplots(1,2)\n",
        "ax0.imshow(im)\n",
        "ax0.set_title(\"Original\")\n",
        "ax1.imshow(recon)\n",
        "ax1.set_title(\"Recon\")\n",
        "plt.tight_layout()\n",
        "plt.savefig('test.png', bbox_inches='tight')\n",
        "#plt.show()\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In[6]:\n",
        "'''\n",
        "\n",
        "im = load_im_into_format_from_path('experiment_images/church.jpg')\n",
        "prompt = 'A church'\n",
        "run_baseline = True # Try vanilla DDIM\n",
        "\n",
        "latents = coupled_stablediffusion(prompt,\n",
        "                               reverse=True,\n",
        "                                init_image=im,\n",
        "                                run_baseline=run_baseline,\n",
        "                               )\n",
        "if run_baseline:\n",
        "    latents = latents[0]\n",
        "recon = coupled_stablediffusion(prompt,\n",
        "                               reverse=False,\n",
        "                                fixed_starting_latent=latents,\n",
        "                                run_baseline=run_baseline,\n",
        "                               )\n",
        "recon = recon[0]\n",
        "\n",
        "fig, (ax0, ax1) = plt.subplots(1,2)\n",
        "ax0.imshow(im)\n",
        "ax0.set_title(\"Original\")\n",
        "ax1.imshow(recon)\n",
        "ax1.set_title(\"Recon\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "'''\n",
        "\n",
        "###########################################################\n",
        "\n",
        "# # Editing\n",
        "#\n",
        "#\n",
        "# We provide a function `EDICT_editing` which accepts an image path, base prompt (original description) and desired edit prompt (target description).\n",
        "\n",
        "'''\n",
        "#test EDICT\n",
        "im_path = 'experiment_images/imagenet_cake.jpg'\n",
        "base_prompt = 'A cupcake'\n",
        "#display(load_im_into_format_from_path(im_path))\n",
        "for edit_prompt in [#'An Easter cupcake',\n",
        "                   #'A hedgehog cupcake',\n",
        "                   #'An England Union Jack cupcake',\n",
        "                   'A Chinese New Year cupcake',\n",
        "                   #'A rainbow cupcake'\n",
        "                   ]:\n",
        "    print(edit_prompt)\n",
        "    #display(EDICT_editing(im_path,\n",
        "    #          base_prompt,\n",
        "    #          edit_prompt)[0])\n",
        "    plot_EDICT_outputs(EDICT_editing(im_path,\n",
        "              base_prompt,\n",
        "              edit_prompt))\n",
        "'''\n",
        "\n",
        "\n",
        "#test BDIA\n",
        "#im_path = 'experiment_images/beach_chair.jpg'\n",
        "#im_path = 'experiment_images/imagenet_lake.jpg'\n",
        "#im_path = 'experiment_images/knight.jpg'\n",
        "#im_path = 'experiment_images/pixabay_car2.jpg'\n",
        "im_path = 'experiment_images/woman-657753_512.jpg'\n",
        "im = load_im_into_format_from_path(im_path)\n",
        "\n",
        "\n",
        "#im.save(\"red_chair.png\",\"PNG\")\n",
        "im.save(\"boy_original.png\",\"PNG\")\n",
        "base_prompt = 'a woman'\n",
        "prompt_list_boy = [\"an old woman\",\n",
        "                  \"a girl\",\n",
        "                  \"a woman with black hair\"\n",
        "                  ]\n",
        "file_name_boy = [\"woman_old\",\n",
        "                 \"woman_girl\",\n",
        "                 \"woman_blackhair\"]\n",
        "\n",
        "#prompt_list_car = [\"a truck\",\n",
        "#                   \"a motocycle\",\n",
        "#                   ]\n",
        "#file_name_car = [\"car_truck\",\n",
        "#                  \"car_motocycle\"]\n",
        "\"\"\"\n",
        "prompt_list_boy = [\"a girl\",\n",
        "                  \"a boy with a moustache\",\n",
        "                  \"a boy with a smile\"\n",
        "                  ]\n",
        "file_name_boy = [\"boy_girl\",\n",
        "                 \"boy_moustache\",\n",
        "                 \"boy_smile\"]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "#base_prompt = 'A statue'\n",
        "prompt_list_statue = [#'A statue with with raised arms',\n",
        "                   #'A statue walking',\n",
        "                   #'A statue from behind',\n",
        "                   #'A statue standing alone giving a thumbs-up',\n",
        "                   ]\n",
        "file_name_statue = [#\"statue_arm\",\n",
        "                    #\"statue_walking\",\n",
        "                    #\"statue_behind\",\n",
        "                    #\"statue_thumb\"\n",
        "                    ]\n",
        "\n",
        "\n",
        "\n",
        "prompt_list_lake = [#'A giraffe in a lake',\n",
        "                   #'A bird above a lake',\n",
        "                   #'A car stuck in a lake',\n",
        "                   #'A castle overlooking a lake',\n",
        "                   #'A fountain in a lake',\n",
        "                   ]\n",
        "file_name_lake = [#'lake_giraffe',\n",
        "                  #\"lake_bird\",\n",
        "                  #\"lake_car\",\n",
        "                  #\"lake_castle\",\n",
        "                  #\"lake_fountain\",\n",
        "                  ]\n",
        "\n",
        "\n",
        "#display(load_im_into_format_from_path(im_path))\n",
        "i=0\n",
        "for edit_prompt in prompt_list_boy:\n",
        "    print(edit_prompt)\n",
        "    im_edit=BDIAV3_editing(im_path, base_prompt, edit_prompt, steps=50)\n",
        "    im_edit[0].save(file_name_boy[i]+\".png\" , \"PNG\")\n",
        "    i+=1\n",
        "    #display(EDICT_editing(im_path,\n",
        "    #          base_prompt,\n",
        "    #          edit_prompt)[0])\n",
        "    #plot_EDICT_outputs()\n",
        "    #recon = recon[0]\n",
        "\n",
        "\n",
        "'''\n",
        "#im_path = 'experiment_images/beach_chair.jpg'\n",
        "im_path = 'experiment_images/imagenet_lake.jpg'\n",
        "im = load_im_into_format_from_path(im_path)\n",
        "\n",
        "#im.save(\"red_chair.png\",\"PNG\")\n",
        "im.save(\"lake.png\",\"PNG\")\n",
        "base_prompt = 'A lake'\n",
        "prompt_list_chair = ['A red chair at the Grand Canyon',\n",
        "                   'A red chair on a fied of grass',\n",
        "                   'A red chair covered in snow in the mountains',\n",
        "                   'A red chair after a flood',\n",
        "                   ]\n",
        "file_name_chair = [\"grand_canyan\", \"grass\", \"snow\", \"flood\"]\n",
        "\n",
        "prompt_list_lake = ['A giraffe in a lake',\n",
        "                   'A bird above a lake',\n",
        "                   'A car stuck in a lake',\n",
        "                   'A castle overlooking a lake',\n",
        "                   'A fountain in a lake',\n",
        "                   ]\n",
        "file_name_lake = ['lake_giraffe',\n",
        "                  \"lake_bird\",\n",
        "                  \"lake_car\",\n",
        "                  \"lake_castle\",\n",
        "                  \"lake_fountain\",\n",
        "                  ]\n",
        "\n",
        "\n",
        "#display(load_im_into_format_from_path(im_path))\n",
        "i=0\n",
        "for edit_prompt in prompt_list_lake:\n",
        "    print(edit_prompt)\n",
        "    im_edit=BDIAV3_editing(im_path, base_prompt, edit_prompt, steps=50)\n",
        "    im_edit[0].save(file_name_lake[i]+\".png\" , \"PNG\")\n",
        "    i+=1\n",
        "    #display(EDICT_editing(im_path,\n",
        "    #          base_prompt,\n",
        "    #          edit_prompt)[0])\n",
        "    #plot_EDICT_outputs()\n",
        "    #recon = recon[0]\n",
        "'''\n",
        "\n",
        "'''\n",
        "im_path = 'experiment_images/imagenet_cake.jpg'\n",
        "base_prompt = 'A cupcake'\n",
        "#display(load_im_into_format_from_path(im_path))\n",
        "for edit_prompt in [#'An Easter cupcake',\n",
        "                   #'A hedgehog cupcake',\n",
        "                   #'An England Union Jack cupcake',\n",
        "                   #'A Chinese New Year cupcake',\n",
        "                   'A rainbow cupcake'\n",
        "                   ]:\n",
        "    print(edit_prompt)\n",
        "    #display(EDICT_editing(im_path,\n",
        "    #          base_prompt,\n",
        "    #          edit_prompt)[0])\n",
        "    plot_EDICT_outputs(BDIA_editing(im_path,\n",
        "              base_prompt,\n",
        "              edit_prompt))\n",
        "'''\n",
        "\n",
        "'''\n",
        "\n",
        "im_path = 'experiment_images/imagenet_camel.jpg'\n",
        "display(load_im_into_format_from_path(im_path))\n",
        "EDICT_editing(im_path,\n",
        "              'Camel by a fence with a sign',\n",
        "              'Camel by a fence',\n",
        "             run_baseline=False,\n",
        "             init_image_strength=0.8)[0]\n",
        "\n",
        "\n",
        "# Functionality to re-create the dog image edits from our paper (Figures 1 and S16-22)\n",
        "\n",
        "# In[9]:\n",
        "\n",
        "\n",
        "for i in range(1, 8):\n",
        "    im_path = f'experiment_images/imagenet_dog_{i}.jpg'\n",
        "    base_prompt = 'A dog' # poodle, dalmatian, lab, german shepherd\n",
        "    print(\"Original\")\n",
        "    display(load_im_into_format_from_path(im_path))\n",
        "    for breed in ['golden retriever', 'chihuahua', 'poodle', 'dalmatian', 'german shepherd', 'husky']:\n",
        "        print(i, breed)\n",
        "        edit_prompt = f'A {breed}'\n",
        "        im0, im0v2 = EDICT_editing(im_path,\n",
        "                  base_prompt,\n",
        "                  edit_prompt,\n",
        "                 run_baseline=False)\n",
        "        display(im0)\n",
        "        display(im0v2)\n",
        "\n",
        "\n",
        "# # Testing on more images\n",
        "#\n",
        "# We provide many of the images displayed in the paper in the [experiment_images/](experiment_images/) folder.\n",
        "#\n",
        "# We highly encourage you to test EDICT on in-the-wild images! Editing success varies across images, but generally meaningful edits can be performed. Consider for example [this wikimedia image](https://upload.wikimedia.org/wikipedia/commons/a/a6/Aurora_in_Abisko_near_Tornetr%C3%A4sk.jpg) that was the [Picture of the Day](https://commons.wikimedia.org/wiki/Commons:Picture_of_the_day) while writing this open-source notebook (Dec. 5 2022).\n",
        "#\n",
        "# First we retrieve the image\n",
        "\n",
        "# In[10]:\n",
        "\n",
        "\n",
        "get_ipython().system(' mkdir web_images')\n",
        "get_ipython().system(' wget https://upload.wikimedia.org/wikipedia/commons/a/a6/Aurora_in_Abisko_near_Tornetr%C3%A4sk.jpg -O web_images/aurora.jpg')\n",
        "\n",
        "\n",
        "# Let's check it out\n",
        "\n",
        "# In[11]:\n",
        "\n",
        "\n",
        "im_path = 'web_images/aurora.jpg'\n",
        "display(load_im_into_format_from_path(im_path))\n",
        "\n",
        "\n",
        "# In[12]:\n",
        "\n",
        "\n",
        "EDICT_editing(im_path,\n",
        "              'A green aurora over a snowy landscape',\n",
        "              'A polar bear watching a green aurora over a snowy landscape',\n",
        "             run_baseline=False,\n",
        "             init_image_strength=0.8)[0]\n",
        "\n",
        "\n",
        "# In[13]:\n",
        "\n",
        "\n",
        "EDICT_editing(im_path,\n",
        "              'A green aurora over a snowy landscape',\n",
        "              'A red aurora over a snowy landscape',\n",
        "             run_baseline=False,\n",
        "             init_image_strength=0.8)[0]\n",
        "\n",
        "\n",
        "# In[14]:\n",
        "\n",
        "\n",
        "EDICT_editing(im_path,\n",
        "              'A green aurora over a snowy landscape',\n",
        "              'A couple getting their photo taken in front of a green aurora over a snowy landscape',\n",
        "             run_baseline=False,\n",
        "             init_image_strength=0.8)[0]\n",
        "# Here we notice the scenery changing\n",
        "# Let's see what we can make it change to if we try\n",
        "\n",
        "\n",
        "# In[15]:\n",
        "\n",
        "\n",
        "EDICT_editing(im_path,\n",
        "              'A green aurora over a snowy landscape',\n",
        "              'A green aurora over mountains', # fairly guaranteed this would work from previous edit mistake\n",
        "             run_baseline=False,\n",
        "             init_image_strength=0.8)[0]\n",
        "\n",
        "\n",
        "# In[16]:\n",
        "\n",
        "\n",
        "EDICT_editing(im_path,\n",
        "              'A green aurora over a snowy landscape',\n",
        "              'A green aurora over a snowy lake',\n",
        "             run_baseline=False,\n",
        "             init_image_strength=0.8)[0]\n",
        "\n",
        "\n",
        "# In[17]:\n",
        "\n",
        "\n",
        "EDICT_editing(im_path,\n",
        "              'A green aurora over a snowy landscape',\n",
        "              'A green aurora over a forest',\n",
        "             run_baseline=False,\n",
        "             init_image_strength=0.8)[0]\n",
        "\n",
        "\n",
        "# # Happy Edi(c)ting!\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKQ4bH7qMGrA"
      },
      "source": [
        "# Making the most of your colab subscription\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5F3-0vDLwt7d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa-IrJS1aRVJ"
      },
      "source": [
        "In order to use a GPU with your notebook, select the <code>Runtime &gt; Change runtime type</code> menu, and then set the hardware accelerator drop-down to GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## More memory\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to high-memory VMs when they are available.\n",
        "You can see how much memory you have available at any time by running the following code cell. If the execution result of running the code cell below is 'Not using a high-RAM runtime', then you can enable a high-RAM runtime via <code>Runtime &gt; Change runtime type</code> in the menu. Then select High-RAM in the Runtime shape drop-down. After, re-execute the code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJW8Qi-pPpep"
      },
      "source": [
        "## Longer runtimes\n",
        "\n",
        "All Colab runtimes are reset after some period of time &#40;which is faster if the runtime isn't executing code&#41;. Colab Pro and Pro+ users have access to longer runtimes than those who use Colab free of charge.\n",
        "\n",
        "## Background execution\n",
        "\n",
        "Colab Pro+ users have access to background execution, where notebooks will continue executing even after you've closed a browser tab. This is always enabled in Pro+ runtimes as long as you have compute units available.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLlTRcMM_h0k"
      },
      "source": [
        "## Relaxing resource limits in Colab Pro\n",
        "\n",
        "Your resources are not unlimited in Colab. To make the most of Colab, avoid using resources when you don't need them. For example, only use a GPU when required and close Colab tabs when finished.\n",
        "\n",
        "If you encounter limitations, you can relax those limitations by purchasing more compute units via pay as you go. Anyone can purchase compute units via <a href=\"https://colab.research.google.com/signup\">pay as you go</a>; no subscription is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm8FzEidvPs6"
      },
      "source": [
        "## Send us feedback!\n",
        "\n",
        "<p>If you have any feedback for us, please let us know. The best way to send feedback is by using the Help &gt; 'Send feedback…' menu. If you encounter usage limits in Colab Pro consider subscribing to Pro+.</p>\n",
        "<p>If you encounter errors or other issues with billing &#40;payments&#41; for Colab Pro, Pro+ or pay as you go, please email <a href=\"mailto:colab-billing@google.com\">colab-billing@google.com</a>.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB3bdLe8jkAa"
      },
      "source": [
        "## More resources\n",
        "\n",
        "### Working with notebooks in Colab\n",
        "- [Overview of Colaboratory](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide to markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "\n",
        "<a name=\"working-with-data\"></a>\n",
        "### Working with data\n",
        "- [Loading data: Drive, Sheets and Google Cloud Storage](/notebooks/io.ipynb)\n",
        "- [Charts: visualising data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine learning crash course\n",
        "These are a few of the notebooks from Google's online machine learning course. See the <a href=\"https://developers.google.com/machine-learning/crash-course/\">full course website</a> for more.\n",
        "- [Intro to Pandas DataFrame](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n",
        "- [Linear regression with tf.keras using synthetic data](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb)\n",
        "\n",
        "\n",
        "<a name=\"using-accelerated-hardware\"></a>\n",
        "### Using accelerated hardware\n",
        "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
        "- [TensorFlow with TPUs](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFm2S0Gijqo8"
      },
      "source": [
        "<a name=\"machine-learning-examples\"></a>\n",
        "\n",
        "## Machine learning examples\n",
        "\n",
        "To see end-to-end examples of the interactive machine-learning analyses that Colaboratory makes possible, take a look at these tutorials using models from <a href=\"https://tfhub.dev\">TensorFlow Hub</a>.\n",
        "\n",
        "A few featured examples:\n",
        "\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tf2_image_retraining\">Retraining an Image Classifier</a>: Build a Keras model on top of a pre-trained image classifier to distinguish flowers.\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tf2_text_classification\">Text Classification</a>: Classify IMDB film reviews as either <em>positive</em> or <em>negative</em>.\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization\">Style Transfer</a>: Use deep learning to transfer style between images.\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa\">Multilingual Universal Sentence Encoder Q&amp;A</a>: Use a machine-learning model to answer questions from the SQuAD dataset.\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tweening_conv3d\">Video Interpolation</a>: Predict what happened in a video between the first and the last frame.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}